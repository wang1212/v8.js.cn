<!doctype html><html lang=zh-CN><meta charset=utf-8><title>An internship on laziness: lazy unlinking of deoptimized functions · V8</title><meta content="width=device-width,initial-scale=1" name=viewport><meta content="dark light" name=color-scheme><link href=/_css/main.css rel=stylesheet><link href=/.webmanifest rel=manifest><meta content=#4285F4 name=theme-color><link href=/blog.atom rel=alternate title="V8 Atom feed" type=application/atom+xml><link href=/features.atom rel=alternate title="V8 JS/Wasm features Atom feed" type=application/atom+xml><script>document.documentElement.className+=' js'</script><meta content="This technical deep-dive explains how V8 used to unlink deoptimized functions, and how we recently changed this to improve performance." name=description><header id=header><h1><a href=/ >V8</a></h1><a href=#navigation-toggle id=nav-toggle>显示导肮</a><nav><ul><li><a href=/ >主页</a><li class=active><a href=/blog/ >博客</a><li><a href=/docs/ >文档</a><li><a href=/features title="JavaScript 和 WebAssembly 的新特性">JS/Wasm 新特性</a><li><a href=/grant>Research</a></ul></nav></header><main id=main><article itemscope itemtype=http://schema.org/BlogPosting><header><h1 itemprop=headline>An internship on laziness: lazy unlinking of deoptimized functions</h1><p class=meta>发布时间 <time datetime="2017-10-04 13:33:37" itemprop=datePublished title="2017-10-04 13:33:37">2017-10-04</time> · 标签： <a href=/blog/tags/memory/ class=tag>memory</a> <a href=/blog/tags/internals/ class=tag>internals</a></header><div itemprop=articleBody><p>Roughly three months ago, I joined the V8 team (Google Munich) as an intern and since then I’ve been working on the VM’s <em>Deoptimizer</em> — something completely new to me which proved to be an interesting and challenging project. The first part of my internship focused on <a href=https://docs.google.com/document/d/1ELgd71B6iBaU6UmZ_lvwxf_OrYYnv0e4nuzZpK05-pg/edit>improving the VM security-wise</a>. The second part focused on performance improvements. Namely, on the removal of a data-structure used for the unlinking of previously deoptimized functions, which was a performance bottleneck during garbage collection. This blog post describes this second part of my internship. I’ll explain how V8 used to unlink deoptimized functions, how we changed this, and what performance improvements were obtained.<p>Let’s (very) briefly recap the V8 pipeline for a JavaScript function: V8’s interpreter, Ignition, collects profiling information about that function while interpreting it. Once the function becomes hot, this information is passed to V8’s compiler, TurboFan, which generates optimized machine code. When the profiling information is no longer valid — for example because one of the profiled objects gets a different type during runtime — the optimized machine code might become invalid. In that case, V8 needs to deoptimize it.<figure><img alt="" height=1154 loading=lazy src=/_img/lazy-unlinking/v8-overview.png width=1600><figcaption>An overview of V8, as seen in <a href=https://medium.com/reloading/javascript-start-up-performance-69200f43b201>JavaScript Start-up Performance</a></figcaption></figure><p>Upon optimization, TurboFan generates a code object, i.e. the optimized machine code, for the function under optimization. When this function is invoked the next time, V8 follows the link to optimized code for that function and executes it. Upon deoptimization of this function, we need to unlink the code object in order to make sure that it won’t be executed again. How does that happen?<p>For example, in the following code, the function <code>f1</code> will be invoked many times (always passing an integer as argument). TurboFan then generates machine code for that specific case.<pre class=language-js><code class=language-js><span class="token keyword">function</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token parameter">i</span><span class="token punctuation">)</span> <span class="token operator">=></span> i<span class="token punctuation">;</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// Create a closure.</span><br><span class="token keyword">const</span> f1 <span class="token operator">=</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token comment">// Optimize f1.</span><br><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">var</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">1000</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token function">f1</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>Each function also has a trampoline to the interpreter — more details in these <a href="https://docs.google.com/presentation/d/1Z6oCocRASCfTqGq1GCo1jbULDGS-w-nzxkbVF7Up0u0/edit#slide=id.p">slides</a> — and will keep a pointer to this trampoline in its <code>SharedFunctionInfo</code> (SFI). This trampoline will be used whenever V8 needs to go back to unoptimized code. Thus, upon deoptimization, triggered by passing an argument of a different type, for example, the Deoptimizer can simply set the code field of the JavaScript function to this trampoline.<figure><img alt="" height=1154 loading=lazy src=/_img/lazy-unlinking/v8-overview.png width=1600><figcaption>An overview of V8, as seen in <a href=https://medium.com/reloading/javascript-start-up-performance-69200f43b201>JavaScript Start-up Performance</a></figcaption></figure><p>Although this seems simple, it forces V8 to keep weak lists of optimized JavaScript functions. This is because it is possible to have different functions pointing to the same optimized code object. We can extend our example as follows, and the functions <code>f1</code> and <code>f2</code> both point to the same optimized code.<pre class=language-js><code class=language-js><span class="token keyword">const</span> f2 <span class="token operator">=</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token function">f2</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>If the function <code>f1</code> is deoptimized (for example by invoking it with an object of different type <code>{x: 0}</code>) we need to make sure that the invalidated code will not be executed again by invoking <code>f2</code>.<p>Thus, upon deoptimization, V8 used to iterate over all the optimized JavaScript functions, and would unlink those that pointed to the code object being deoptimized. This iteration in applications with many optimized JavaScript functions became a performance bottleneck. Moreover, other than slowing down deoptimization, V8 used to iterate over these lists upon stop-the-world cycles of garbage collection, making it even worse.<p>In order to have an idea of the impact of such data-structure in the performance of V8, we wrote a <a href=https://github.com/v8/v8/blob/master/test/js-perf-test/ManyClosures/create-many-closures.js>micro-benchmark</a> that stresses its usage, by triggering many scavenge cycles after creating many JavaScript functions.<pre class=language-js><code class=language-js><span class="token keyword">function</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token parameter">i</span><span class="token punctuation">)</span> <span class="token operator">=></span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// Create an initial closure and optimize.</span><br><span class="token keyword">var</span> f <span class="token operator">=</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token function">f</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token function">f</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token operator">%</span><span class="token function">OptimizeFunctionOnNextCall</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token function">f</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Create 2M closures; those will get the previously optimized code.</span><br><span class="token keyword">var</span> a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span><br><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">var</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">2000000</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">var</span> h <span class="token operator">=</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token function">h</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  a<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// Now cause scavenges; all of them are slow.</span><br><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">var</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">1000</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">new</span> <span class="token class-name">Array</span><span class="token punctuation">(</span><span class="token number">50000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span></code></pre><p>When running this benchmark, we could observe that V8 spent around 98% of its execution time on garbage collection. We then removed this data structure, and instead used an approach for <em>lazy unlinking</em>, and this was what we observed on x64:<figure><img alt="" height=766 loading=lazy src=/_img/lazy-unlinking/microbenchmark-results.png width=1240></figure><p>Although this is just a micro-benchmark that creates many JavaScript functions and triggers many garbage collection cycles, it gives us an idea of the overhead introduced by this data structure. Other more realistic applications where we saw some overhead, and which motivated this work, were the <a href=https://github.com/delvedor/router-benchmark>router benchmark</a> implemented in Node.js and <a href=http://browserbench.org/ARES-6/ >ARES-6 benchmark suite</a>.<h2 id=lazy-unlinking>Lazy unlinking <a href=#lazy-unlinking class=bookmark>#</a></h2><p>Rather than unlinking optimized code from JavaScript functions upon deoptimization, V8 postpones it for the next invocation of such functions. When such functions are invoked, V8 checks whether they have been deoptimized, unlinks them and then continues with their lazy compilation. If these functions are never invoked again, then they will never be unlinked and the deoptimized code objects will not be collected. However, given that during deoptimization, we invalidate all the embedded fields of the code object, we only keep that code object alive.<p>The <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690>commit</a> that removed this list of optimized JavaScript functions required changes in several parts of the VM, but the basic idea is as follows. When assembling the optimized code object, we check if this is the code of a JavaScript function. If so, in its prologue, we assemble machine code to bail out if the code object has been deoptimized. Upon deoptimization we don’t modify the deoptimized code — code patching is gone. Thus, its bit <code>marked_for_deoptimization</code> is still set when invoking the function again. TurboFan generates code to check it, and if it is set, then V8 jumps to a new builtin, <code>CompileLazyDeoptimizedCode</code>, that unlinks the deoptimized code from the JavaScript function and then continues with lazy compilation.<p>In more detail, the first step is to generate instructions that load the address of the code being currently assembled. We can do that in x64, with the following code:<pre class=language-cpp><code class=language-cpp>Label current<span class="token punctuation">;</span><br><span class="token comment">// Load effective address of current instruction into rcx.</span><br>__ <span class="token function">leaq</span><span class="token punctuation">(</span>rcx<span class="token punctuation">,</span> <span class="token function">Operand</span><span class="token punctuation">(</span><span class="token operator">&</span>current<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>__ <span class="token function">bind</span><span class="token punctuation">(</span><span class="token operator">&</span>current<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>After that we need to obtain where in the code object the <code>marked_for_deoptimization</code> bit lives.<pre class=language-cpp><code class=language-cpp><span class="token keyword">int</span> pc <span class="token operator">=</span> __ <span class="token function">pc_offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">int</span> offset <span class="token operator">=</span> Code<span class="token operator">::</span>kKindSpecificFlags1Offset <span class="token operator">-</span> <span class="token punctuation">(</span>Code<span class="token operator">::</span>kHeaderSize <span class="token operator">+</span> pc<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>We can then test the bit and if it is set, we jump to the <code>CompileLazyDeoptimizedCode</code> built in.<pre class=language-cpp><code class=language-cpp><span class="token comment">// Test if the bit is set, that is, if the code is marked for deoptimization.</span><br>__ <span class="token function">testl</span><span class="token punctuation">(</span><span class="token function">Operand</span><span class="token punctuation">(</span>rcx<span class="token punctuation">,</span> offset<span class="token punctuation">)</span><span class="token punctuation">,</span><br>         <span class="token function">Immediate</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> Code<span class="token operator">::</span>kMarkedForDeoptimizationBit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token comment">// Jump to builtin if it is.</span><br>__ <span class="token function">j</span><span class="token punctuation">(</span>not_zero<span class="token punctuation">,</span> <span class="token comment">/* handle to builtin code here */</span><span class="token punctuation">,</span> RelocInfo<span class="token operator">::</span>CODE_TARGET<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>On the side of this <code>CompileLazyDeoptimizedCode</code> builtin, all that’s left to do is to unlink the code field from the JavaScript function and set it to the trampoline to the Interpreter entry. So, considering that the address of the JavaScript function is in the register <code>rdi</code>, we can obtain the pointer to the <code>SharedFunctionInfo</code> with:<pre class=language-cpp><code class=language-cpp><span class="token comment">// Field read to obtain the SharedFunctionInfo.</span><br>__ <span class="token function">movq</span><span class="token punctuation">(</span>rcx<span class="token punctuation">,</span> <span class="token function">FieldOperand</span><span class="token punctuation">(</span>rdi<span class="token punctuation">,</span> JSFunction<span class="token operator">::</span>kSharedFunctionInfoOffset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>…and similarly the trampoline with:<pre class=language-cpp><code class=language-cpp><span class="token comment">// Field read to obtain the code object.</span><br>__ <span class="token function">movq</span><span class="token punctuation">(</span>rcx<span class="token punctuation">,</span> <span class="token function">FieldOperand</span><span class="token punctuation">(</span>rcx<span class="token punctuation">,</span> SharedFunctionInfo<span class="token operator">::</span>kCodeOffset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>Then we can use it to update the function slot for the code pointer:<pre class=language-cpp><code class=language-cpp><span class="token comment">// Update the code field of the function with the trampoline.</span><br>__ <span class="token function">movq</span><span class="token punctuation">(</span><span class="token function">FieldOperand</span><span class="token punctuation">(</span>rdi<span class="token punctuation">,</span> JSFunction<span class="token operator">::</span>kCodeOffset<span class="token punctuation">)</span><span class="token punctuation">,</span> rcx<span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token comment">// Write barrier to protect the field.</span><br>__ <span class="token function">RecordWriteField</span><span class="token punctuation">(</span>rdi<span class="token punctuation">,</span> JSFunction<span class="token operator">::</span>kCodeOffset<span class="token punctuation">,</span> rcx<span class="token punctuation">,</span> r15<span class="token punctuation">,</span><br>                    kDontSaveFPRegs<span class="token punctuation">,</span> OMIT_REMEMBERED_SET<span class="token punctuation">,</span> OMIT_SMI_CHECK<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>This produces the same result as before. However, rather than taking care of the unlinking in the Deoptimizer, we need to worry about it during code generation. Hence the handwritten assembly.<p>The above is <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690#diff-0920a0f56f95b36cdd43120466ec7ccd>how it works in the x64 architecture</a>. We have implemented it for <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690#diff-10985b50f31627688e9399a768d9ec21>ia32</a>, <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690#diff-0f5515e80dd0139244a4ae48ce56a139>arm</a>, <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690#diff-1bbe32f45000ec9157f4997a6c95f1b1>arm64</a>, <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690#diff-73f690ee13a5465909ae9fc1a70d8c41>mips</a>, and <a href=https://github.com/v8/v8/commit/f0acede9bb05155c25ee87e81b4b587e8a76f690#diff-b1de25cbfd2d02b81962797bfdf807df>mips64</a> as well.<p>This new technique is already integrated in V8 and, as we’ll discuss later, allows for performance improvements. However, it comes with a minor disadvantage: Before, V8 would consider unlinking only upon deoptimization. Now, it has to do so in the activation of all optimized functions. Moreover, the approach to check the <code>marked_for_deoptimization</code> bit is not as efficient as it could be, given that we need to do some work to obtain the address of the code object. Note that this happens when entering every optimized function. A possible solution for this issue is to keep in a code object a pointer to itself. Rather than doing work to find the address of the code object whenever the function is invoked, V8 would do it only once, after its construction.<h2 id=results>Results <a href=#results class=bookmark>#</a></h2><p>We now look at the performance gains and regressions obtained with this project.<h3 id=general-improvements-on-x64>General improvements on x64 <a href=#general-improvements-on-x64 class=bookmark>#</a></h3><p>The following plot shows us some improvements and regressions, relative to the previous commit. Note that the higher, the better.<figure><img alt="" height=880 loading=lazy src=/_img/lazy-unlinking/x64.png width=1200></figure><p>The <code>promises</code> benchmarks are the ones where we see greater improvements, observing almost 33% gain for the <code>bluebird-parallel</code> benchmark, and 22.40% for <code>wikipedia</code>. We also observed a few regressions in some benchmarks. This is related to the issue explained above, on checking whether the code is marked for deoptimization.<p>We also see improvements in the ARES-6 benchmark suite. Note that in this chart too, the higher the better. These programs used to spend considerable amount of time in GC-related activities. With lazy unlinking we improve performance by 1.9% overall. The most notable case is the <code>Air steadyState</code> where we get an improvement of around 5.36%.<figure><img alt="" height=371 loading=lazy src=/_img/lazy-unlinking/ares6.png width=600></figure><h3 id=arewefastyet-results>AreWeFastYet results <a href=#arewefastyet-results class=bookmark>#</a></h3><p>The performance results for the Octane and ARES-6 benchmark suites also showed up on the AreWeFastYet tracker. We looked at these performance results on September 5th, 2017, using the provided default machine (macOS 10.10 64-bit, Mac Pro, shell).<figure><img alt="" height=734 loading=lazy src=/_img/lazy-unlinking/awfy-octane.png width=1236><figcaption>Cross-browser results on Octane as seen on AreWeFastYet</figcaption></figure><figure><img alt="" height=756 loading=lazy src=/_img/lazy-unlinking/awfy-ares6.png width=1236><figcaption>Cross-browser results on ARES-6 as seen on AreWeFastYet</figcaption></figure><h3 id=impact-on-node.js>Impact on Node.js <a href=#impact-on-node.js class=bookmark>#</a></h3><p>We can also see performance improvements in the <code>router-benchmark</code>. The following two plots show the number of operations per second of each tested router. Thus the higher the better. We have performed two kinds of experiments with this benchmark suite. Firstly, we ran each test in isolation, so that we could see the performance improvement, independently from the remaining tests. Secondly, we ran all tests at once, without switching of the VM, thus simulating an environment where each test is integrated with other functionalities.<p>For the first experiment, we saw that the <code>router</code> and <code>express</code> tests perform about twice as many operations than before, in the same amount of time. For the second experiment, we saw even greater improvement. In some of the cases, such as <code>routr</code>, <code>server-router</code> and <code>router</code>, the benchmark performs approximately 3.80×, 3× and 2× more operations, respectively. This happens because V8 accumulates more optimized JavaScript functions, test after test. Thus, whenever executing a given test, if a garbage collection cycle is triggered, V8 has to visit the optimized functions from the current test and from the previous ones.<figure><img alt="" height=371 loading=lazy src=/_img/lazy-unlinking/router.png width=600></figure><figure><img alt="" height=371 loading=lazy src=/_img/lazy-unlinking/router-integrated.png width=600></figure><h3 id=further-optimization>Further optimization <a href=#further-optimization class=bookmark>#</a></h3><p>Now that V8 does not keep the linked-list of JavaScript functions in the context, we can remove the field <code>next</code> from the <code>JSFunction</code> class. Although this is a simple modification, it allows us to save the size of a pointer per function, which represent significant savings in several web pages:<div class=table-wrapper><table><thead><tr><th>Benchmark<th>Kind<th>Memory savings (absolute)<th>Memory savings (relative)<tbody><tr><td>facebook.com<td>Average effective size<td>170 KB<td>3.70%<tr><td>twitter.com<td>Average size of allocated objects<td>284 KB<td>1.20%<tr><td>cnn.com<td>Average size of allocated objects<td>788 KB<td>1.53%<tr><td>youtube.com<td>Average size of allocated objects<td>129 KB<td>0.79%</table></div><h2 id=acknowledgments>Acknowledgments <a href=#acknowledgments class=bookmark>#</a></h2><p>Throughout my internship, I had lots of help from several people, who were always available to answer my many questions. Thus I would like to thank the following people: Benedikt Meurer, Jaroslav Sevcik, and Michael Starzinger for discussions on how the compiler and the deoptimizer work, Ulan Degenbaev for helping with the garbage collector whenever I broke it, and Mathias Bynens, Peter Marshall, Camillo Bruni, and Maya Armyanova for proofreading this article.<p>Finally, this article is my last contribution as a Google intern and I would like to take the opportunity to thank everyone in the V8 team, and especially my host, Benedikt Meurer, for hosting me and for giving me the opportunity to work on such an interesting project — I definitely learned a lot and enjoyed my time at Google!</div><footer><div><p>作者：Juliana Franco (<a href=https://twitter.com/jupvfranco>@jupvfranco</a>), Laziness Expert.</div><a href=https://twitter.com/v8js/status/915473224187760640 class=retweet>Retweet this article!</a></footer></article></main><footer id=footer><div><nav><a href=https://v8.dev/blog/lazy-unlinking>原文</a> · <a href=/logo/ >商标</a> · <a href=/terms/ >条款</a> · <a href=https://policies.google.com/privacy/ >隐私</a> · <a href=https://twitter.com/v8js rel="me nofollow">Twitter</a> · <a href=https://github.com/justjavac/v8.js.cn/tree/master/./src/blog/lazy-unlinking.md rel=nofollow>在 GitHub 编辑此页面</a></nav><dark-mode-toggle dark="Light Theme" light="Dark Theme" permanent></dark-mode-toggle></div><p><small>如无特殊说明，此 V8 项目中使用到的所有示例代码均基于 <a href=https://chromium.googlesource.com/v8/v8.git/+/master/LICENSE>V8's BSD-style license</a> 发布。页面中的文字内容采用 <a href=https://creativecommons.org/licenses/by/3.0/ >the Creative Commons Attribution 3.0 License</a> 进行许可。更详细的信息可以在 <a href=/terms#site-policies>站点策略</a> 中找到。</small></footer><script src=/_js/dark-mode-toggle.mjs type=module></script><script src=/_js/main.mjs type=module></script><script src=/_js/legacy.js nomodule></script>