<!doctype html><html lang=zh-CN><meta charset=utf-8><title>Liftoff: a new baseline compiler for WebAssembly in V8 · V8</title><meta content="width=device-width,initial-scale=1" name=viewport><meta content="dark light" name=color-scheme><link href=/_css/main.css rel=stylesheet><link href=/.webmanifest rel=manifest><meta content=#4285F4 name=theme-color><link href=/blog.atom rel=alternate title="V8 Atom feed" type=application/atom+xml><link href=/features.atom rel=alternate title="V8 JS/Wasm features Atom feed" type=application/atom+xml><script>document.documentElement.className+=' js'</script><meta content="Liftoff is a new baseline compiler for WebAssembly, shipping in V8 v6.9." name=description><header id=header><h1><a href=/ >V8</a></h1><a href=#navigation-toggle id=nav-toggle>显示导肮</a><nav><ul><li><a href=/ >主页</a><li class=active><a href=/blog/ >博客</a><li><a href=/docs/ >文档</a><li><a href=/features title="JavaScript 和 WebAssembly 的新特性">JS/Wasm 新特性</a><li><a href=/grant>Research</a></ul></nav></header><main id=main><article itemscope itemtype=http://schema.org/BlogPosting><header><h1 itemprop=headline>Liftoff: a new baseline compiler for WebAssembly in V8</h1><p class=meta>发布时间 <time datetime="2018-08-20 15:45:12" itemprop=datePublished title="2018-08-20 15:45:12">2018-08-20</time> · 标签： <a href=/blog/tags/webassembly/ class=tag>WebAssembly</a> <a href=/blog/tags/internals/ class=tag>internals</a></header><div itemprop=articleBody><p>V8 <a href=/blog/v8-release-69>v6.9</a> includes Liftoff, a new baseline compiler for WebAssembly. Liftoff is now enabled by default on desktop systems. This article details the motivation to add another compilation tier and describes the implementation and performance of Liftoff.<figure><img alt="" height=256 loading=lazy src=/_img/v8-liftoff.svg width=256><figcaption>Logo for Liftoff, V8’s WebAssembly baseline compiler</figcaption></figure><p>Since WebAssembly <a href=/blog/v8-release-57>launched</a> more than a year ago, adoption on the web has been steadily increasing. Big applications targeting WebAssembly have started to appear. For example, Epic’s <a href=https://s3.amazonaws.com/mozilla-games/ZenGarden/EpicZenGarden.html>ZenGarden benchmark</a> comprises a 39.5 MB WebAssembly binary, and <a href=https://web.autocad.com/ >AutoDesk</a> ships as a 36.8 MB binary. Since compilation time is essentially linear in the binary size, these applications take a considerable time to start up. On many machines it’s more than 30 seconds, which does not provide a great user experience.<p>But why does it take this long to start up a WebAssembly app, if similar JS apps start up much faster? The reason is that WebAssembly promises to deliver <em>predictable performance</em>, so once the app is running, you can be sure to consistently meet your performance goals (e.g. rendering 60 frames per second, no audio lag or artifacts…). In order to achieve this, WebAssembly code is compiled <em>ahead of time</em> in V8, to avoid any compilation pause introduced by a just-in-time compiler that could result in visible jank in the app.<h2 id=the-existing-compilation-pipeline-(turbofan)>The existing compilation pipeline (TurboFan) <a href=#the-existing-compilation-pipeline-(turbofan) class=bookmark>#</a></h2><p>V8’s approach to compiling WebAssembly has relied on <em>TurboFan</em>, the optimizing compiler we designed for JavaScript and asm.js. TurboFan is a powerful compiler with a graph-based <em>intermediate representation (IR)</em> suitable for advanced optimizations such as strength reduction, inlining, code motion, instruction combining, and sophisticated register allocation. TurboFan’s design supports entering the pipeline very late, nearer to machine code, which bypasses many of the stages necessary for supporting JavaScript compilation. By design, transforming WebAssembly code into TurboFan’s IR (including <a href=https://en.wikipedia.org/wiki/Static_single_assignment_form><em>SSA-construction</em></a>) in a straightforward single pass is very efficient, partially due to WebAssembly’s structured control flow. Yet the backend of the compilation process still consumes considerable time and memory.<h2 id=the-new-compilation-pipeline-(liftoff)>The new compilation pipeline (Liftoff) <a href=#the-new-compilation-pipeline-(liftoff) class=bookmark>#</a></h2><p>The goal of Liftoff is to reduce startup time for WebAssembly-based apps by generating code as fast as possible. Code quality is secondary, as hot code is eventually recompiled with TurboFan anyway. Liftoff avoids the time and memory overhead of constructing an IR and generates machine code in a single pass over the bytecode of a WebAssembly function.<figure><img alt="" height=470 loading=lazy src=/_img/liftoff/pipeline.svg width=701><figcaption>The Liftoff compilation pipeline is much simpler compared to the TurboFan compilation pipeline.</figcaption></figure><p>From the diagram above it is obvious that Liftoff should be able to generate code much faster than TurboFan since the pipeline only consists of two stages. In fact, the <em>function body decoder</em> does a single pass over the raw WebAssembly bytes and interacts with the subsequent stage via callbacks, so <em>code generation</em> is performed <em>while decoding and validating</em> the function body. Together with WebAssembly’s <em><a href=/blog/v8-release-65>streaming APIs</a></em>, this allows V8 to compile WebAssembly code to machine code while downloading over the network.<h3 id=code-generation-in-liftoff>Code generation in Liftoff <a href=#code-generation-in-liftoff class=bookmark>#</a></h3><p>Liftoff is a simple code generator, and fast. It performs only one pass over the opcodes of a function, generating code for each opcode, one at a time. For simple opcodes like arithmetics, this is often a single machine instruction, but can be more for others like calls. Liftoff maintains metadata about the operand stack in order to know where the inputs of each operation are currently stored. This <em>virtual stack</em> exists only during compilation. WebAssembly’s structured control flow and validation rules guarantee that the location of these inputs can be statically determined. Thus an actual runtime stack onto which operands are pushed and popped is not necessary. During execution, each value on the virtual stack will either be held in a register or be spilled to the physical stack frame of that function. For small integer constants (generated by <code>i32.const</code>), Liftoff only records the constant’s value in the virtual stack and does not generate any code. Only when the constant is used by a subsequent operation, it is emitted or combined with the operation, for example by directly emitting a <code>addl &lt;reg>, &lt;const></code> instruction on x64. This avoids ever loading that constant into a register, resulting in better code.<p>Let’s go through a very simple function to see how Liftoff generates code for that.<figure><img alt="" height=700 loading=lazy src=/_img/liftoff/example-1.svg width=808></figure><p>This example function takes two parameters and returns their sum. When Liftoff decodes the bytes of this function, it first begins by initializing its internal state for the local variables according to the calling convention for WebAssembly functions. For x64, V8’s calling convention passes the two parameters in the registers <em>rax</em> and <em>rdx</em>.<p>For <code>get_local</code> instructions, Liftoff does not generate any code, but instead just updates its internal state to reflect that these register values are now pushed on the virtual stack. The <code>i32.add</code> instruction then pops the two registers and chooses a register for the result value. We cannot use any of the input registers for the result, since both registers still appear on the stack for holding the local variables. Overwriting them would change the value returned by a later <code>get_local</code> instruction. So Liftoff picks a free register, in this case <em>rcx</em>, and produce the sum of <em>rax</em> and <em>rdx</em> into that register. <em>rcx</em> is then pushed onto the virtual stack.<p>After the <code>i32.add</code> instruction, the function body is finished, so Liftoff must assemble the function return. As our example function has one return value, validation requires that there must be exactly one value on the virtual stack at the end of the function body. So Liftoff generates code that moves the return value held in <em>rcx</em> into the proper return register <em>rax</em> and then returns from the function.<p>For the sake of simplicity, the example above does not contain any blocks (<code>if</code>, <code>loop</code> …) or branches. Blocks in WebAssembly introduce control merges, since code can branch to any parent block, and if-blocks can be skipped. These merge points can be reached from different stack states. Following code, however, has to assume a specific stack state to generate code. Thus, Liftoff snapshots the current state of the virtual stack as the state which will be assumed for code following the new block (i.e. when returning to the <em>control level</em> where we currently are). The new block will then continue with the currently active state, potentially changing where stack values or locals are stored: some might be spilled to the stack or held in other registers. When branching to another block or ending a block (which is the same as branching to the parent block), Liftoff must generate code that adapts the current state to the expected state at that point, such that the code emitted for the target we branch to finds the right values where it expects them. Validation guarantees that the height of the current virtual stack matches the height of the expected state, so Liftoff need only generate code to shuffle values between registers and/or the physical stack frame as shown below.<p>Let’s look at an example of that.<figure><img alt="" height=590 loading=lazy src=/_img/liftoff/example-2.svg width=946></figure><p>The example above assumes a virtual stack with two values on the operand stack. Before starting the new block, the top value on the virtual stack is popped as argument to the <code>if</code> instruction. The remaining stack value needs to be put in another register, since it is currently shadowing the first parameter, but when branching back to this state we might need to hold two different values for the stack value and the parameter. In this case Liftoff chooses to deduplicate it into the <em>rcx</em> register. This state is then snapshotted, and the active state is modified within the block. At the end of the block, we implicitly branch back to the parent block, so we merge the current state into the snapshot by moving register <em>rbx</em> into <em>rcx</em> and reloading register <em>rdx</em> from the stack frame.<h3 id=tiering-up-from-liftoff-to-turbofan>Tiering up from Liftoff to TurboFan <a href=#tiering-up-from-liftoff-to-turbofan class=bookmark>#</a></h3><p>With Liftoff and TurboFan, V8 now has two compilation tiers for WebAssembly: Liftoff as the baseline compiler for fast startup and TurboFan as optimizing compiler for maximum performance. This poses the question of how to combine the two compilers to provide the best overall user experience.<p>For JavaScript, V8 uses the Ignition interpreter and the TurboFan compiler and employs a dynamic tier-up strategy. Each function is first executed in Ignition, and if the function becomes hot, TurboFan compiles it into highly-optimized machine code. A similar approach could also be used for Liftoff, but the tradeoffs are a bit different here:<ol><li>WebAssembly does not require type feedback to generate fast code. Where JavaScript greatly benefits from gathering type feedback, WebAssembly is statically typed, so the engine can generate optimized code right away.<li>WebAssembly code should run <em>predictably</em> fast, without a lengthy warm-up phase. One of the reasons applications target WebAssembly is to execute on the web <em>with predictable high performance</em>. So we can neither tolerate running suboptimal code for too long, nor do we accept compilation pauses during execution.<li>An important design goal of the Ignition interpreter for JavaScript is to reduce memory usage by not compiling functions at all. Yet we found that an interpreter for WebAssembly is far too slow to deliver on the goal of predictably fast performance. We did, in fact, build such an interpreter, but being 20× or more slower than compiled code, it is only useful for debugging, regardless of how much memory it saves. Given this, the engine must store compiled code anyway; in the end it should store only the most compact and most efficient code, which is TurboFan optimized code.</ol><p>From these constraints we concluded that dynamic tier-up is not the right tradeoff for V8’s implementation of WebAssembly right now, since it would increase code size and reduce performance for an indeterminate time span. Instead, we chose a strategy of <em>eager tier-up</em>. Immediately after Liftoff compilation of a module finished, the WebAssembly engine starts background threads to generate optimized code for the module. This allows V8 to start executing code quickly (after Liftoff finished), but still have the most performant TurboFan code available as early as possible.<p>The picture below shows the trace of compiling and executing <a href=https://s3.amazonaws.com/mozilla-games/ZenGarden/EpicZenGarden.html>the EpicZenGarden benchmark</a>. It shows that right after Liftoff compilation we can instantiate the WebAssembly module and start executing it. TurboFan compilation still takes several more seconds, so during that tier-up period the observed execution performance gradually increases since individual TurboFan functions are used as soon as they are finished.<figure><img alt="" height=723 loading=lazy src=/_img/liftoff/tierup-liftoff-turbofan.png width=890></figure><h2 id=performance>Performance <a href=#performance class=bookmark>#</a></h2><p>Two metrics are interesting for evaluating the performance of the new Liftoff compiler. First we want to compare the compilation speed (i.e. time to generate code) with TurboFan. Second, we want to measure the performance of the generated code (i.e. execution speed). The first measure is the more interesting here, since the goal of Liftoff is to reduce startup time by generating code as quickly as possible. On the other hand, the performance of the generated code should still be pretty good since that code might still execute for several seconds or even minutes on low-end hardware.<h3 id=performance-of-generating-code>Performance of generating code <a href=#performance-of-generating-code class=bookmark>#</a></h3><p>For measuring the <em>compiler performance</em> itself, we ran a number of benchmarks and measured the raw compilation time using tracing (see picture above). We run both benchmarks on an HP Z840 machine (2 x Intel Xeon E5-2690 @2.6GHz, 24 cores, 48 threads) and on a Macbook Pro (Intel Core i7-4980HQ @2.8GHz, 4 cores, 8 threads). Note that Chrome does currently not use more than 10 background threads, so most of the cores of the Z840 machine are unused.<p>We execute three benchmarks:<ol><li><a href=https://s3.amazonaws.com/mozilla-games/ZenGarden/EpicZenGarden.html><strong>EpicZenGarden</strong></a>: The ZenGarden demo running on the Epic framework<li><a href=https://webassembly.org/demo/ ><strong>Tanks!</strong></a>: A demo of the Unity engine<li><a href=https://web.autocad.com/ ><strong>AutoDesk</strong></a><li><a href=https://pspdfkit.com/webassembly-benchmark/ ><strong>PSPDFKit</strong></a></ol><p>For each benchmark, we measure the raw compilation time using the tracing output as shown above. This number is more stable than any time reported by the benchmark itself, as it does not rely on a task being scheduled on the main thread and does not include unrelated work like creating the actual WebAssembly instance.<p>The graphs below show the results of these benchmarks. Each benchmark was executed three times, and we report the average compilation time.<figure><img alt="" height=282 loading=lazy src=/_img/liftoff/performance-unity-macbook.svg width=490><figcaption>Code generation performance of Liftoff vs. TurboFan on a MacBook</figcaption></figure><figure><img alt="" height=282 loading=lazy src=/_img/liftoff/performance-unity-z840.svg width=490><figcaption>Code generation performance of Liftoff vs. TurboFan on a Z840</figcaption></figure><p>As expected, the Liftoff compiler generates code much faster both on the high-end desktop workstation as well as on the MacBook. The speedup of Liftoff over TurboFan is even bigger on the less-capable MacBook hardware.<h3 id=performance-of-the-generated-code>Performance of the generated code <a href=#performance-of-the-generated-code class=bookmark>#</a></h3><p>Even though performance of the generated code is a secondary goal, we want to preserve user experience with high performance in the startup phase, as Liftoff code might execute for several seconds before TurboFan code is finished.<p>For measuring Liftoff code performance, we turned off tier-up in order to measure pure Liftoff execution. In this setup, we execute two benchmarks:<ol><li><p><strong>Unity headless benchmarks</strong><p>This is a number of benchmarks running in the Unity framework. They are headless, hence can be executed in the d8 shell directly. Each benchmark reports a score, which is not necessarily proportional to the execution performance, but good enough to compare the performance.<li><p><a href=https://pspdfkit.com/webassembly-benchmark/ ><strong>PSPDFKit</strong></a><p>This benchmark reports the time it takes to perform different actions on a pdf document and the time it takes to instantiate the WebAssembly module (including compilation).</ol><p>Just as before, we execute each benchmark three times and use the average of the three runs. Since the scale of the recorded numbers differs significantly between the benchmarks, we report the <em>relative performance of Liftoff vs. TurboFan</em>. A value of <em>+30%</em> means that Liftoff code runs 30% slower than TurboFan. Negative numbers indicate that Liftoff executes faster. Here are the results:<figure><img alt="" height=371 loading=lazy src=/_img/liftoff/performance-unity-compile.svg width=600><figcaption>Liftoff Performance on Unity</figcaption></figure><p>On Unity, Liftoff code execute on average around 50% slower than TurboFan code on the desktop machine and 70% slower on the MacBook. Interestingly, there is one case (Mandelbrot Script) where Liftoff code outperforms TurboFan code. This is likely an outlier where, for example, the register allocator of TurboFan is doing poorly in a hot loop. We are investigating to see if TurboFan can be improved to handle this case better.<figure><img alt="" height=371 loading=lazy src=/_img/liftoff/performance-pspdfkit-compile.svg width=600><figcaption>Liftoff Performance on PSPDFKit</figcaption></figure><p>On the PSPDFKit benchmark, Liftoff code executes 18-54% slower than optimized code, while initialization improves significantly, as expected. These numbers show that for real-world code which also interacts with the browser via JavaScript calls, the performance loss of unoptimized code is generally lower than on more computation-intensive benchmarks.<p>And again, note that for these numbers we turned off tier-up completely, so we only ever executed Liftoff code. In production configurations, Liftoff code will gradually be replaced by TurboFan code, such that the lower performance of Liftoff code lasts only for short period of time.<h2 id=future-work>Future work <a href=#future-work class=bookmark>#</a></h2><p>After the initial launch of Liftoff, we are working to further improve startup time, reduce memory usage, and bring the benefits of Liftoff to more users. In particular, we are working on improving the following things:<ol><li><strong>Port Liftoff to arm and arm64 to also use it on mobile devices.</strong> Currently, Liftoff is only implemented for Intel platforms (32 and 64 bit), which mostly captures desktop use cases. In order to also reach mobile users, we will port Liftoff to more architectures.<li><strong>Implement dynamic tier-up for mobile devices.</strong> Since mobile devices tend to have much less memory available than desktop systems, we need to adapt our tiering strategy for these devices. Just recompiling all functions with TurboFan easily doubles the memory needed to hold all code, at least temporarily (until Liftoff code is discarded). Instead, we are experimenting with a combination of lazy compilation with Liftoff and dynamic tier-up of hot functions in TurboFan.<li><strong>Improve performance of Liftoff code generation.</strong> The first iteration of an implementation is rarely the best one. There are several things which can be tuned to speed up the compilation speed of Liftoff even more. This will gradually happen over the next releases.<li><strong>Improve performance of Liftoff code.</strong> Apart from the compiler itself, the size and speed of the generated code can also be improved. This will also happen gradually over the next releases.</ol><h2 id=conclusion>Conclusion <a href=#conclusion class=bookmark>#</a></h2><p>V8 now contains Liftoff, a new baseline compiler for WebAssembly. Liftoff vastly reduces start-up time of WebAssembly applications with a simple and fast code generator. On desktop systems, V8 still reaches maximum peak performance by recompiling all code in the background using TurboFan. Liftoff is enabled by default in V8 v6.9 (Chrome 69), and can be controlled explicitly with the <code>--liftoff</code>/<code>--no-liftoff</code> and <code>chrome://flags/#enable-webassembly-baseline</code> flags in each, respectively.</div><footer><div><picture><source srcset="/_img/avatars/clemens-backes.avif, /_img/avatars/clemens-backes@2x.avif 2x" type=image/avif><img alt="" height=96 loading=lazy src=/_img/avatars/clemens-backes.jpg width=96 srcset="/_img/avatars/clemens-backes@2x.jpg 2x"></picture><p>作者：Clemens Backes, WebAssembly compilation maestro.</div><a href=https://twitter.com/v8js/status/1031538167617413120 class=retweet>Retweet this article!</a></footer></article></main><footer id=footer><div><nav><a href=https://v8.dev/blog/liftoff>原文</a> · <a href=/logo/ >商标</a> · <a href=/terms/ >条款</a> · <a href=https://policies.google.com/privacy/ >隐私</a> · <a href=https://twitter.com/v8js rel="me nofollow">Twitter</a> · <a href=https://github.com/justjavac/v8.js.cn/tree/master/./src/blog/liftoff.md rel=nofollow>在 GitHub 编辑此页面</a></nav><dark-mode-toggle dark="Light Theme" light="Dark Theme" permanent></dark-mode-toggle></div><p><small>如无特殊说明，此 V8 项目中使用到的所有示例代码均基于 <a href=https://chromium.googlesource.com/v8/v8.git/+/master/LICENSE>V8's BSD-style license</a> 发布。页面中的文字内容采用 <a href=https://creativecommons.org/licenses/by/3.0/ >the Creative Commons Attribution 3.0 License</a> 进行许可。更详细的信息可以在 <a href=/terms#site-policies>站点策略</a> 中找到。</small></footer><script src=/_js/dark-mode-toggle.mjs type=module></script><script src=/_js/main.mjs type=module></script><script src=/_js/legacy.js nomodule></script>