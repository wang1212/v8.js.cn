<!doctype html><html lang=zh-CN><meta charset=utf-8><title>Fast, parallel applications with WebAssembly SIMD · V8</title><meta content="width=device-width,initial-scale=1" name=viewport><meta content="dark light" name=color-scheme><link href=/_css/main.css rel=stylesheet><link href=/_css/feature-support.css rel=stylesheet><link href=/.webmanifest rel=manifest><meta content=#4285F4 name=theme-color><link href=/blog.atom rel=alternate title="V8 Atom feed" type=application/atom+xml><link href=/features.atom rel=alternate title="V8 JS/Wasm features Atom feed" type=application/atom+xml><script>document.documentElement.className+=' js'</script><meta content="Bringing vector operations to WebAssembly" name=description><header id=header><h1><a href=/ >V8</a></h1><a href=#navigation-toggle id=nav-toggle>显示导肮</a><nav><ul><li><a href=/ >主页</a><li><a href=/blog/ >博客</a><li><a href=/docs/ >文档</a><li class=current><a href=/features title="JavaScript 和 WebAssembly 的新特性">JS/Wasm 新特性</a><li><a href=/grant>Research</a></ul></nav></header><main id=main><article itemscope itemtype=http://schema.org/BlogPosting><header><h1 itemprop=headline>Fast, parallel applications with WebAssembly SIMD</h1><p class=meta>发布时间 <time datetime="2020-01-30 00:00:00" itemprop=datePublished>2020-01-30</time> · 更新时间 <time datetime="2020-06-09 00:00:00" itemprop=dateModified>2020-06-09</time> · 标签： <a href=/features/tags/webassembly class=tag>WebAssembly</a></header><div itemprop=articleBody><p>SIMD stands for <em>Single Instruction, Multiple Data</em>. SIMD instructions are a special class of instructions that exploit data parallelism in applications by simultaneously performing the same operation on multiple data elements. Compute intensive applications like audio/video codecs, image processors, are all examples of applications that take advantage of SIMD instructions to accelerate performance. Most modern architectures support some variants of SIMD instructions.<p>The WebAssembly SIMD proposal defines a portable, performant subset of SIMD operations that are available across most modern architectures. This proposal derived many elements from the <a href=https://github.com/tc39/ecmascript_simd>SIMD.js proposal</a>, which in turn was originally derived from the <a href=https://www.researchgate.net/publication/261959129_A_SIMD_programming_model_for_dart_javascriptand_other_dynamically_typed_scripting_languages>Dart SIMD</a> specification. The SIMD.js proposal was an API proposed at TC39 with new types and functions for performing SIMD computations, but this was archived in favor of supporting SIMD operations more transparently in WebAssembly. The <a href=https://github.com/WebAssembly/simd>WebAssembly SIMD proposal</a> was introduced as a way for browsers to take advantage of the data level parallelism using the underlying hardware.<h2 id=webassembly-simd-proposal>WebAssembly SIMD proposal <a href=#webassembly-simd-proposal class=bookmark>#</a></h2><p>The high-level goal of the WebAssembly SIMD proposal is to introduce vector operations to the WebAssembly Specification, in a way that guarantees portable performance.<p>The set of SIMD instructions is large, and varied across architectures. The set of operations included in the WebAssembly SIMD proposal consist of operations that are well supported on a wide variety of platforms, and are proven to be performant. To this end, the current proposal is limited to standardizing Fixed-Width 128-bit SIMD operations.<p>The current proposal introduces a new v128 value type, and a number of new operations that operate on this type. The criteria used to determine these operations are:<ul><li>The operations should be well supported across multiple modern architectures.<li>Performance wins should be positive across multiple relevant architectures within an instruction group.<li>The chosen set of operations should minimize performance cliffs if any.</ul><p>The proposal is in active development, both V8 and the toolchain have working prototype implementations for experimentation. As these are prototype implementations, they are subject to change as new operations are added to the proposal.<h2 id=using-webassembly-simd>Using WebAssembly SIMD <a href=#using-webassembly-simd class=bookmark>#</a></h2><h3 id=enabling-experimental-simd-support-in-chrome>Enabling experimental SIMD support in Chrome <a href=#enabling-experimental-simd-support-in-chrome class=bookmark>#</a></h3><p>WebAssembly SIMD support is prototyped behind a flag in Chrome, to try out the SIMD support on the browser, pass <code>--enable-features=WebAssemblySimd</code>, or toggle the "WebAssembly SIMD support" flag in <code>chrome://flags</code>. This work is bleeding edge, and continuously being worked on. To minimize the chances of breakage, please use the latest version of the toolchain as detailed below, and a recent Chrome Canary. If something doesn’t look right, please <a href=https://crbug.com/v8>file a bug</a>.<h3 id=building-c-%2F-c%2B%2B-to-target-simd>Building C / C++ to target SIMD <a href=#building-c-%2F-c%2B%2B-to-target-simd class=bookmark>#</a></h3><p>WebAssembly’s SIMD support depends on using a recent build of clang with the WebAssembly LLVM backend enabled. Emscripten has support for the WebAssembly SIMD proposal as well. Install and activate the latest-upstream distribution of emscripten using <a href=https://emscripten.org/docs/getting_started/downloads.html>emsdk</a> to use the bleeding edge SIMD features.<pre class=language-bash><code class=language-bash>./emsdk <span class="token function">install</span> latest-upstream<br><br>./emsdk activate latest-upstream</code></pre><p>There are a couple of different ways to enable generating SIMD code when porting your application to use SIMD. Once the latest upstream emscripten version has been installed, compile using emscripten, and pass the <code>-msimd128</code> flag to enable SIMD.<pre class=language-bash><code class=language-bash>emcc -msimd128 -O3 foo.c -o foo.js</code></pre><p>Applications that have already been ported to use WebAssembly may benefit from SIMD with no source modifications thanks to LLVM’s autovectorization optimizations.<p>These optimizations can automatically transform loops that perform arithmetic operations on each iteration into equivalent loops that perform the same arithmetic operations on multiple inputs at a time using SIMD instructions. LLVM’s autovectorizers are enabled by default at optimization levels <code>-O2</code> and <code>-O3</code> when the <code>-msimd128</code> flag is supplied.<p>For example, consider the following function that multiplies the elements of two input arrays together and stores the results in an output array.<pre class=language-cpp><code class=language-cpp><span class="token keyword">void</span> <span class="token function">multiply_arrays</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> out<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> in_a<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> in_b<span class="token punctuation">,</span> <span class="token keyword">int</span> size<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    out<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> in_a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> in_b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre><p>Without passing the <code>-msimd128</code> flag, the compiler emits this WebAssembly loop:<pre class=language-wasm><code class=language-wasm><span class="token punctuation">(</span><span class="token keyword">loop</span><br>  <span class="token punctuation">(</span><span class="token keyword">i32<span class="token punctuation">.</span>store</span><br>    … get address in `out` …<br>    <span class="token punctuation">(</span><span class="token keyword">i32<span class="token punctuation">.</span>mul</span><br>      <span class="token punctuation">(</span><span class="token keyword">i32<span class="token punctuation">.</span>load</span> … get address in `in_a` …<span class="token punctuation">)</span><br>      <span class="token punctuation">(</span><span class="token keyword">i32<span class="token punctuation">.</span>load</span> … get address in `in_b` …<span class="token punctuation">)</span><br>  …<br><span class="token punctuation">)</span></code></pre><p>But when the <code>-msimd128</code> flag is used, the autovectorizer turns this into code that includes the following loop:<pre class=language-wasm><code class=language-wasm><span class="token punctuation">(</span><span class="token keyword">loop</span><br>  <span class="token punctuation">(</span>v128.store <span class="token keyword">align<span class="token operator">=</span></span><span class="token number">4</span><br>    … get address in `out` …<br>    <span class="token punctuation">(</span>i32x4.mul<br>       <span class="token punctuation">(</span>v128.load <span class="token keyword">align<span class="token operator">=</span></span><span class="token number">4</span> … get address in `in_a` …<span class="token punctuation">)</span><br>       <span class="token punctuation">(</span>v128.load <span class="token keyword">align<span class="token operator">=</span></span><span class="token number">4</span> … get address in `in_b` …<span class="token punctuation">)</span><br>    …<br>  <span class="token punctuation">)</span><br><span class="token punctuation">)</span></code></pre><p>The loop body has the same structure but SIMD instructions are being used to load, multiply, and store four elements at a time inside the loop body.<p>For finer grained control over the SIMD instructions generated by the compiler, include the <a href=https://github.com/llvm/llvm-project/blob/master/clang/lib/Headers/wasm_simd128.h><code>wasm_simd128.h</code> header file</a>, which defines a set of intrinsics. Intrinsics are special functions that, when called, will be turned by the compiler into the corresponding WebAssembly SIMD instructions, unless it can make further optimizations.<p>As an example, here is the same function from before manually rewritten to use the SIMD intrinsics.<pre class=language-cpp><code class=language-cpp><span class="token macro property"><span class="token directive-hash">#</span><span class="token keyword directive">include</span> <span class="token string">&lt;wasm_simd128.h></span></span><br><br><span class="token keyword">void</span> <span class="token function">multiply_arrays</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> out<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> in_a<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> in_b<span class="token punctuation">,</span> <span class="token keyword">int</span> size<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i <span class="token operator">+=</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    v128_t a <span class="token operator">=</span> <span class="token function">wasm_v128_load</span><span class="token punctuation">(</span><span class="token operator">&</span>in_a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    v128_t b <span class="token operator">=</span> <span class="token function">wasm_v128_load</span><span class="token punctuation">(</span><span class="token operator">&</span>in_b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    v128_t prod <span class="token operator">=</span> <span class="token function">wasm_i32x4_mul</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token function">wasm_v128_store</span><span class="token punctuation">(</span><span class="token operator">&</span>out<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> prod<span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre><p>This manually rewritten code assumes that the input and output arrays are aligned and do not alias and that size is a multiple of four. The autovectorizer cannot make these assumptions and has to generate extra code to handle the cases where they are not true, so hand-written SIMD code often ends up being smaller than autovectorized SIMD code.<h2 id=compelling-use-cases>Compelling use cases <a href=#compelling-use-cases class=bookmark>#</a></h2><p>The WebAssembly SIMD proposal seeks to accelerate high compute applications like audio/video codecs, image processing applications, cryptographic applications, etc. Currently WebAssembly SIMD is experimentally supported in widely used open source projects like <a href=https://github.com/halide/Halide/blob/master/README_webassembly.md>Halide</a>, <a href=https://docs.opencv.org/3.4/d5/d10/tutorial_js_root.html>OpenCV.js</a>, and <a href=https://github.com/google/XNNPACK>XNNPACK</a>.<p>Some interesting demos come from the <a href=https://github.com/google/mediapipe>MediaPipe project</a> by the Google Research team.<p>As per their description, MediaPipe is a framework for building multimodal (eg. video, audio, any time series data) applied ML pipelines. And they have a <a href=https://mediapipe.page.link/web>Web version</a>, too!<p>One of the most visually appealing demos where it’s easy to observe the difference in performance SIMD makes, is a following hand-tracking system. Without SIMD, you can get only around 3 frames per second on a modern laptop, while with SIMD enabled you get a much smoother experience at 15-16 frames per second.<figure><video autoplay height=216 loop muted playsinline src=/_img/simd/hand.mp4 width=600></video></figure><p>Visit the <a href=https://pursuit.page.link/MediaPipeHandTrackingSimd>demo</a> in Chrome Canary with SIMD enabled to try it!<p>Another interesting set of demos that makes use of SIMD for smooth experience, come from OpenCV - a popular computer vision library that can also be compiled to WebAssembly. They’re available by <a href=https://bit.ly/opencv-camera-demos>link</a>, or you can check out the pre-recorded versions below:<figure><video autoplay height=512 loop muted playsinline src=/_img/simd/credit-card.mp4 width=256></video><figcaption>Card reading</figcaption></figure><figure><video autoplay height=646 loop muted playsinline src=/_img/simd/invisibility-cloak.mp4 width=600></video><figcaption>Invisibility cloak</figcaption></figure><figure><video autoplay height=658 loop muted playsinline src=/_img/simd/emotion-recognizer.mp4 width=600></video><figcaption>Emoji replacement</figcaption></figure><h2 id=simd-origin-trial>SIMD Origin Trial <a href=#simd-origin-trial class=bookmark>#</a></h2><p>The WebAssembly SIMD origin trial is available for experimentation in Chrome versions 84-86. Origin trials allow developers to experiment with a feature, and provide valuable feedback. Once an origin trial token has been registered, the trial users are opted into the feature for the duration of the trial period without having to update Chrome flags.<p>To try this out, read the <a href=https://github.com/GoogleChrome/OriginTrials/blob/gh-pages/developer-guide.md>origin trial developer guide</a>, and <a href=https://developers.chrome.com/origintrials/#/view_trial/-4708513410415853567>register for an origin trial token</a>. More information about origin trials can be found in the <a href=https://github.com/GoogleChrome/OriginTrials/blob/gh-pages/developer-guide.md#faq>FAQ</a>, please file a <a href=https://bugs.chromium.org/p/v8/issues/entry>bug</a> if something isn't working as you expect. The origin trial is compatible with emscripten versions 1.39.15 onwards.<p>Ongoing experimental support is available on a recent Chrome Canary as detailed <a href=#using-webassembly-simd>above</a>, with the use of latest-upstream Emscripten toolchain.<h2 id=future-work>Future work <a href=#future-work class=bookmark>#</a></h2><p>The current SIMD proposal is in <a href=https://github.com/WebAssembly/meetings/blob/master/process/phases.md#3-implementation-phase-community--working-group>Phase 3</a>, so the future work here is to push the proposal forward in the standardization process. Fixed width SIMD gives significant performance gains over scalar, but it doesn’t effectively leverage wider width vector operations that are available in modern hardware. As the current proposal moves forward, some future facing work here is to determine the feasibility of extending the proposal with longer width operations.</div><footer><div><p>作者：Deepti Gandluri (<a href=https://twitter.com/dptig>@dptig</a>), Thomas Lively (<a href=https://twitter.com/tlively52>@tlively52</a>).</div><a href=https://twitter.com/v8js/status/1222944308183085058 class=retweet>Retweet this article!</a></footer></article></main><footer id=footer><div><nav><a href=https://v8.dev/features/simd>原文</a> · <a href=/logo/ >商标</a> · <a href=/terms/ >条款</a> · <a href=https://policies.google.com/privacy/ >隐私</a> · <a href=https://twitter.com/v8js rel="me nofollow">Twitter</a> · <a href=https://github.com/justjavac/v8.js.cn/tree/master/./src/features/simd.md rel=nofollow>在 GitHub 编辑此页面</a></nav><dark-mode-toggle dark="Light Theme" light="Dark Theme" permanent></dark-mode-toggle></div><p><small>如无特殊说明，此 V8 项目中使用到的所有示例代码均基于 <a href=https://chromium.googlesource.com/v8/v8.git/+/master/LICENSE>V8's BSD-style license</a> 发布。页面中的文字内容采用 <a href=https://creativecommons.org/licenses/by/3.0/ >the Creative Commons Attribution 3.0 License</a> 进行许可。更详细的信息可以在 <a href=/terms#site-policies>站点策略</a> 中找到。</small></footer><script src=/_js/dark-mode-toggle.mjs type=module></script><script src=/_js/main.mjs type=module></script><script src=/_js/legacy.js nomodule></script>